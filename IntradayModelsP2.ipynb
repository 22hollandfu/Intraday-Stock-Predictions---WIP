{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dupaw\\AppData\\Local\\Temp\\ipykernel_14456\\2875046767.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Input, Dropout, BatchNormalization, Reshape, Bidirectional, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras_tuner import Hyperband, HyperParameters\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to modularize repeated things I want to do (loading data, custom accuracy test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data function\n",
    "stock = {\n",
    "    'AAPL': 'AAPL_1min_firstratedata.csv',\n",
    "    'AMZN': 'AMZN_1min_firstratedata.csv',\n",
    "    'META': 'META_1min_firstratedata.csv',\n",
    "    'TSLA': 'TSLA_1min_firstratedata.csv',\n",
    "    'MSFT': 'MSFT_1min_firstratedata.csv'\n",
    "}\n",
    "# define scalar and early stopping as global variables\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "def loadData(stock = stock['AAPL'], sequence_length = 10, prediction_length = 1, want_to_plot = False): \n",
    "    \"\"\"\n",
    "    Loads stock data from a CSV file, applies logarithmic transformation to the volume column, \n",
    "    scales the data using a scaler, and formats it into sequences for training a model.\n",
    "\n",
    "    Args:\n",
    "        stock (str): The path to the CSV file containing the stock data. Defaults to 'AAPL'.\n",
    "        sequence_length (int): The length of the input sequences. Defaults to 10.\n",
    "        prediction_length (int): The length of the output sequences. Defaults to 1.\n",
    "        want_to_plot (bool): Whether to plot the data. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the input sequences (x) and the output sequences (y).\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    data = pd.read_csv(stock)\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    data.set_index('timestamp', inplace=True)\n",
    "\n",
    "    if want_to_plot:\n",
    "        # Plotting the data\n",
    "        date = '2022-11-29 12'\n",
    "        data_window = data.loc[date]\n",
    "        mpf.plot(data_window, type='candle', style='charles', volume=True)\n",
    "        print(data)\n",
    "\n",
    "    # Apply logarithmic transformation to the volume column\n",
    "    data['volume'] = np.log(data['volume'])\n",
    "    data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)\n",
    "    \n",
    "    # e.g. for 10 timesteps per 1 prediction (sequence_length = 10)\n",
    "    #  from 10 to ~160k (num observations), append data[0:10] to x for the 10 timesteps to predict data[11], the 11th prediction appended to y\n",
    "    # x.append(data[1:11]) and y.append(data[12]) for the next step, etc\n",
    "    x, y = [], []\n",
    "    for i in range(sequence_length, len(data) - prediction_length + 1):\n",
    "        x.append(data.iloc[i - sequence_length: i])\n",
    "        y.append(data.iloc[i: i + prediction_length])\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x, y\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def calculateAccuracy(model, stock, batch = 32,want_to_print=False):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy of how often a given model predicts the correct direction on a specific stock\n",
    "\n",
    "    Args:\n",
    "        model: The model to evaluate.\n",
    "        stock (str): The path to the CSV file containing the stock data.\n",
    "        batch (int, optional): The batch size for prediction. Defaults to 32.\n",
    "        want_to_print (bool, optional): Whether to print the results. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    x, y = loadData(stock, sequence_length=model.input_shape[1], prediction_length=model.output_shape[1])\n",
    "\n",
    "    # Generate predictions\n",
    "    predictions = model.predict(x, batch_size=batch)\n",
    "\n",
    "    # Check if return_sequences is True or False\n",
    "    if len(predictions.shape) == 3:  # return_sequences=True\n",
    "        n_predictions = predictions.shape[1]\n",
    "        pred_labels = []\n",
    "        true_labels = []\n",
    "\n",
    "        for i in range(n_predictions):  # Loop through each prediction length\n",
    "            pred_labels.append((predictions[:, i, 3] > x[:, -1, 3]).astype(int))\n",
    "            true_labels.append((y[:, i, 3] > x[:, -1, 3]).astype(int))\n",
    "\n",
    "        # Convert lists to numpy arrays\n",
    "        pred_labels = np.array(pred_labels).T  # Transpose to match the shape\n",
    "        true_labels = np.array(true_labels).T  # Transpose to match the shape\n",
    "\n",
    "        # Calculate accuracy for each prediction length\n",
    "        accuracies = []\n",
    "        for i in range(n_predictions):\n",
    "            accuracies.append(accuracy_score(true_labels[:, i], pred_labels[:, i]))\n",
    "\n",
    "        # Calculate the average accuracy\n",
    "        average_accuracy = np.mean(accuracies)\n",
    "        print(f'Average Accuracy: {average_accuracy:.2f}')\n",
    "\n",
    "        # Display the results\n",
    "        results_dict = {\n",
    "            'Previous Close': x[:, -1, 3]\n",
    "        }\n",
    "\n",
    "        for i in range(n_predictions):\n",
    "            results_dict[f'Predicted Close {i+1}'] = predictions[:, i, 3]\n",
    "            results_dict[f'True Close {i+1}'] = y[:, i, 3]\n",
    "            results_dict[f'Predicted Direction {i+1}'] = pred_labels[:, i]\n",
    "            results_dict[f'True Direction {i+1}'] = true_labels[:, i]\n",
    "\n",
    "    else:  # return_sequences=False\n",
    "        pred_labels = (predictions[:, 3] > x[:, -1, 3]).astype(int)\n",
    "        true_labels = (y[:, 0, 3] > x[:, -1, 3]).astype(int)  # Adjusted to match the shape\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(true_labels, pred_labels)\n",
    "        print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "        # Display the results\n",
    "        results_dict = {\n",
    "            'Previous Close': x[:, -1, 3],\n",
    "            'Predicted Close': predictions[:, 3],\n",
    "            'True Close': y[:, 0, 3],  # Adjusted to match the shape\n",
    "            'Predicted Direction': pred_labels,\n",
    "            'True Direction': true_labels\n",
    "        }\n",
    "\n",
    "    results = pd.DataFrame(results_dict)\n",
    "    if want_to_print:\n",
    "        print(results)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data for this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(302623, 40, 5)\n",
      "(53405, 40, 5)\n",
      "(302623, 1, 5)\n",
      "(53405, 1, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "x_aapl, y_aapl = loadData(stock=stock['AAPL'], sequence_length=40, prediction_length=1)\n",
    "x_meta, y_meta = loadData(stock=stock['META'], sequence_length=40, prediction_length=1)\n",
    "\n",
    "# Concatenate the data\n",
    "x_combined = np.concatenate((x_aapl, x_meta), axis=0)\n",
    "y_combined = np.concatenate((y_aapl, y_meta), axis=0)\n",
    "\n",
    "# Split the data into training and validation sets (85% training, 15% validation)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_combined, y_combined, test_size=0.15, random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying a bidirectional LSTM architecture: 2 LSTM, 2 Dense layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">212,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">615,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">71,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,125</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m320\u001b[0m)        │       \u001b[38;5;34m212,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)            │       \u001b[38;5;34m615,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │        \u001b[38;5;34m71,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m1,125\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">901,189</span> (3.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m901,189\u001b[0m (3.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">901,189</span> (3.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m901,189\u001b[0m (3.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 126ms/step - loss: 0.0096 - val_loss: 0.0011 - learning_rate: 6.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 127ms/step - loss: 0.0015 - val_loss: 0.0011 - learning_rate: 6.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m588s\u001b[0m 124ms/step - loss: 0.0013 - val_loss: 0.0011 - learning_rate: 6.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m581s\u001b[0m 123ms/step - loss: 0.0013 - val_loss: 0.0011 - learning_rate: 6.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m575s\u001b[0m 122ms/step - loss: 0.0013 - val_loss: 0.0011 - learning_rate: 6.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m585s\u001b[0m 124ms/step - loss: 0.0012 - val_loss: 0.0010 - learning_rate: 3.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 120ms/step - loss: 0.0012 - val_loss: 0.0010 - learning_rate: 3.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 120ms/step - loss: 0.0012 - val_loss: 9.9476e-04 - learning_rate: 3.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m572s\u001b[0m 121ms/step - loss: 0.0012 - val_loss: 0.0010 - learning_rate: 3.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m576s\u001b[0m 122ms/step - loss: 0.0012 - val_loss: 9.9240e-04 - learning_rate: 3.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 120ms/step - loss: 0.0012 - val_loss: 0.0010 - learning_rate: 1.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m554s\u001b[0m 117ms/step - loss: 0.0012 - val_loss: 9.9189e-04 - learning_rate: 1.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m554s\u001b[0m 117ms/step - loss: 0.0012 - val_loss: 9.9656e-04 - learning_rate: 1.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 117ms/step - loss: 0.0012 - val_loss: 9.7999e-04 - learning_rate: 1.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m553s\u001b[0m 117ms/step - loss: 0.0012 - val_loss: 9.7123e-04 - learning_rate: 7.5000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m573s\u001b[0m 121ms/step - loss: 0.0012 - val_loss: 9.6997e-04 - learning_rate: 7.5000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m576s\u001b[0m 122ms/step - loss: 0.0012 - val_loss: 9.8699e-04 - learning_rate: 7.5000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m591s\u001b[0m 125ms/step - loss: 0.0012 - val_loss: 9.7122e-04 - learning_rate: 7.5000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m586s\u001b[0m 124ms/step - loss: 0.0012 - val_loss: 9.6584e-04 - learning_rate: 3.7500e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m577s\u001b[0m 122ms/step - loss: 0.0012 - val_loss: 9.6478e-04 - learning_rate: 3.7500e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 119ms/step - loss: 0.0012 - val_loss: 9.6836e-04 - learning_rate: 3.7500e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m569s\u001b[0m 120ms/step - loss: 0.0012 - val_loss: 9.6829e-04 - learning_rate: 3.7500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 120ms/step - loss: 0.0011 - val_loss: 9.6946e-04 - learning_rate: 1.8750e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 118ms/step - loss: 0.0012 - val_loss: 9.6236e-04 - learning_rate: 1.8750e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 119ms/step - loss: 0.0012 - val_loss: 9.6119e-04 - learning_rate: 1.8750e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 119ms/step - loss: 0.0012 - val_loss: 9.6202e-04 - learning_rate: 1.8750e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 119ms/step - loss: 0.0012 - val_loss: 9.6060e-04 - learning_rate: 9.3750e-06\n",
      "Epoch 28/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 116ms/step - loss: 0.0011 - val_loss: 9.5975e-04 - learning_rate: 9.3750e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 116ms/step - loss: 0.0011 - val_loss: 9.6129e-04 - learning_rate: 9.3750e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 116ms/step - loss: 0.0012 - val_loss: 9.6042e-04 - learning_rate: 9.3750e-06\n",
      "Epoch 31/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 117ms/step - loss: 0.0011 - val_loss: 9.5970e-04 - learning_rate: 4.6875e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 117ms/step - loss: 0.0011 - val_loss: 9.5942e-04 - learning_rate: 4.6875e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 117ms/step - loss: 0.0012 - val_loss: 9.5926e-04 - learning_rate: 4.6875e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 116ms/step - loss: 0.0012 - val_loss: 9.5935e-04 - learning_rate: 4.6875e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 117ms/step - loss: 0.0012 - val_loss: 9.5956e-04 - learning_rate: 2.3438e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 116ms/step - loss: 0.0011 - val_loss: 9.5902e-04 - learning_rate: 2.3438e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 116ms/step - loss: 0.0011 - val_loss: 9.5943e-04 - learning_rate: 2.3438e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 116ms/step - loss: 0.0012 - val_loss: 9.5873e-04 - learning_rate: 2.3438e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 116ms/step - loss: 0.0012 - val_loss: 9.5920e-04 - learning_rate: 1.1719e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 116ms/step - loss: 0.0012 - val_loss: 9.5869e-04 - learning_rate: 1.1719e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 116ms/step - loss: 0.0012 - val_loss: 9.5894e-04 - learning_rate: 1.1719e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 116ms/step - loss: 0.0011 - val_loss: 9.5849e-04 - learning_rate: 1.1719e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19350s\u001b[0m 4s/step - loss: 0.0011 - val_loss: 9.5899e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 118ms/step - loss: 0.0011 - val_loss: 9.5874e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 133ms/step - loss: 0.0011 - val_loss: 9.5871e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m579s\u001b[0m 122ms/step - loss: 0.0011 - val_loss: 9.5851e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m570s\u001b[0m 121ms/step - loss: 0.0011 - val_loss: 9.5868e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 122ms/step - loss: 0.0011 - val_loss: 9.5821e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 49/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 126ms/step - loss: 0.0011 - val_loss: 9.5894e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m599s\u001b[0m 127ms/step - loss: 0.0012 - val_loss: 9.5853e-04 - learning_rate: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">212,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">615,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">71,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,125</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m320\u001b[0m)        │       \u001b[38;5;34m212,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)            │       \u001b[38;5;34m615,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │        \u001b[38;5;34m71,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m1,125\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,703,569</span> (10.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,703,569\u001b[0m (10.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">901,189</span> (3.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m901,189\u001b[0m (3.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,802,380</span> (6.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,802,380\u001b[0m (6.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-6)\n",
    "checkpoint = ModelCheckpoint('modelmk2-1.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(x_train.shape[1], x_train.shape[2])))\n",
    "\n",
    "# First Bidirectional LSTM layer with return sequences\n",
    "model.add(Bidirectional(LSTM(units=160, activation='relu', return_sequences=True, kernel_regularizer=l2(6e-05))))\n",
    "\n",
    "# Second Bidirectional LSTM layer without return sequences\n",
    "model.add(Bidirectional(LSTM(units=160, activation='relu', return_sequences=False, kernel_regularizer=l2(6e-05))))\n",
    "\n",
    "# Dense layer with 224 units\n",
    "model.add(Dense(units=224, activation='relu'))\n",
    "model.add(Dropout(0.10))  # Dropout layer\n",
    "\n",
    "# Output Dense layer\n",
    "model.add(Dense(units=y_train.shape[1] * y_train.shape[2], activation='relu'))\n",
    "model.add(Reshape((y_train.shape[1], y_train.shape[2])))\n",
    "\n",
    "# Compile the model with the specified learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0006), loss='mse')\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=64, validation_data=(x_val, y_val), callbacks=[early_stopping, lr_scheduler, checkpoint])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying a CNN-LSTM architecture: 2 conv1d -> max pooling -> 2LSTM2Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">144,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">205,440</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,125</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m12,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m160\u001b[0m)        │       \u001b[38;5;34m144,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)            │       \u001b[38;5;34m205,440\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │        \u001b[38;5;34m36,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m1,125\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">400,005</span> (1.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m400,005\u001b[0m (1.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">400,005</span> (1.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m400,005\u001b[0m (1.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 38ms/step - loss: 0.0084 - val_loss: 0.0012 - learning_rate: 6.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0011 - learning_rate: 6.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 36ms/step - loss: 0.0011 - val_loss: 0.0010 - learning_rate: 6.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 37ms/step - loss: 0.0011 - val_loss: 0.0010 - learning_rate: 6.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 37ms/step - loss: 0.0010 - val_loss: 0.0011 - learning_rate: 6.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 37ms/step - loss: 0.0010 - val_loss: 0.0010 - learning_rate: 6.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 37ms/step - loss: 0.0010 - val_loss: 0.0010 - learning_rate: 3.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 37ms/step - loss: 0.0010 - val_loss: 9.8175e-04 - learning_rate: 3.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 37ms/step - loss: 9.9653e-04 - val_loss: 9.7052e-04 - learning_rate: 3.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 37ms/step - loss: 9.8432e-04 - val_loss: 9.8889e-04 - learning_rate: 3.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 37ms/step - loss: 9.8588e-04 - val_loss: 9.7333e-04 - learning_rate: 1.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 37ms/step - loss: 9.8631e-04 - val_loss: 9.5698e-04 - learning_rate: 1.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 37ms/step - loss: 9.6960e-04 - val_loss: 9.6829e-04 - learning_rate: 1.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 37ms/step - loss: 9.7225e-04 - val_loss: 9.6031e-04 - learning_rate: 1.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 36ms/step - loss: 9.6839e-04 - val_loss: 9.5689e-04 - learning_rate: 7.5000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 36ms/step - loss: 9.7216e-04 - val_loss: 9.5553e-04 - learning_rate: 7.5000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 36ms/step - loss: 9.7647e-04 - val_loss: 9.5270e-04 - learning_rate: 7.5000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 37ms/step - loss: 9.6917e-04 - val_loss: 9.6369e-04 - learning_rate: 7.5000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 37ms/step - loss: 9.6630e-04 - val_loss: 9.5230e-04 - learning_rate: 3.7500e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 36ms/step - loss: 9.6134e-04 - val_loss: 9.5476e-04 - learning_rate: 3.7500e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 36ms/step - loss: 9.6808e-04 - val_loss: 9.5325e-04 - learning_rate: 3.7500e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 36ms/step - loss: 9.6211e-04 - val_loss: 9.5437e-04 - learning_rate: 3.7500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 36ms/step - loss: 9.6233e-04 - val_loss: 9.4867e-04 - learning_rate: 1.8750e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 36ms/step - loss: 9.6043e-04 - val_loss: 9.4870e-04 - learning_rate: 1.8750e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 37ms/step - loss: 9.6532e-04 - val_loss: 9.4883e-04 - learning_rate: 1.8750e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 36ms/step - loss: 9.5291e-04 - val_loss: 9.4798e-04 - learning_rate: 1.8750e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 36ms/step - loss: 9.5185e-04 - val_loss: 9.4867e-04 - learning_rate: 1.8750e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 37ms/step - loss: 9.5352e-04 - val_loss: 9.4765e-04 - learning_rate: 9.3750e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 37ms/step - loss: 9.5844e-04 - val_loss: 9.4622e-04 - learning_rate: 9.3750e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 37ms/step - loss: 9.5572e-04 - val_loss: 9.4613e-04 - learning_rate: 9.3750e-06\n",
      "Epoch 31/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 37ms/step - loss: 9.4871e-04 - val_loss: 9.4662e-04 - learning_rate: 9.3750e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 36ms/step - loss: 9.4652e-04 - val_loss: 9.4590e-04 - learning_rate: 4.6875e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 36ms/step - loss: 9.5620e-04 - val_loss: 9.4632e-04 - learning_rate: 4.6875e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 37ms/step - loss: 9.5268e-04 - val_loss: 9.4611e-04 - learning_rate: 4.6875e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 36ms/step - loss: 9.5608e-04 - val_loss: 9.4661e-04 - learning_rate: 4.6875e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 37ms/step - loss: 9.6324e-04 - val_loss: 9.4663e-04 - learning_rate: 2.3438e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 37ms/step - loss: 9.6126e-04 - val_loss: 9.4584e-04 - learning_rate: 2.3438e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 37ms/step - loss: 9.5403e-04 - val_loss: 9.4615e-04 - learning_rate: 2.3438e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 36ms/step - loss: 9.4453e-04 - val_loss: 9.4592e-04 - learning_rate: 2.3438e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 37ms/step - loss: 9.5328e-04 - val_loss: 9.4585e-04 - learning_rate: 1.1719e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 37ms/step - loss: 9.6096e-04 - val_loss: 9.4599e-04 - learning_rate: 1.1719e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 37ms/step - loss: 9.6046e-04 - val_loss: 9.4597e-04 - learning_rate: 1.1719e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 37ms/step - loss: 9.5875e-04 - val_loss: 9.4581e-04 - learning_rate: 1.1719e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 37ms/step - loss: 9.5005e-04 - val_loss: 9.4564e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 36ms/step - loss: 9.4523e-04 - val_loss: 9.4598e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 37ms/step - loss: 9.4830e-04 - val_loss: 9.4573e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 37ms/step - loss: 9.5247e-04 - val_loss: 9.4560e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 37ms/step - loss: 9.4631e-04 - val_loss: 9.4576e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 49/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 37ms/step - loss: 9.5830e-04 - val_loss: 9.4568e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 37ms/step - loss: 9.5675e-04 - val_loss: 9.4565e-04 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-6)\n",
    "checkpoint = ModelCheckpoint('modelmk2-2.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Dropout(0.2))\n",
    "# First Bidirectional LSTM layer with return sequences\n",
    "model.add(LSTM(units=160, activation='relu', return_sequences=True, kernel_regularizer=l2(6e-05)))\n",
    "# Second Bidirectional LSTM layer without return sequences\n",
    "model.add(LSTM(units=160, activation='relu', return_sequences=False, kernel_regularizer=l2(6e-05)))\n",
    "\n",
    "# Dense layer with 224 units\n",
    "model.add(Dense(units=224, activation='relu'))\n",
    "# model.add(Dropout(0.15))  # Dropout layer\n",
    "\n",
    "# Output Dense layer\n",
    "model.add(Dense(units=y_train.shape[1] * y_train.shape[2], activation='relu'))\n",
    "model.add(Reshape((y_train.shape[1], y_train.shape[2])))\n",
    "model.summary()\n",
    "# Compile the model with the specified learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0006), loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=64, validation_data=(x_val, y_val), callbacks=[early_stopping, lr_scheduler, checkpoint])\n",
    "\n",
    "# Print the model summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing MSE, MAPE, and custom accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7212/7212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 9ms/step\n",
      "Mean Squared Error (Unscaled): 0.5307263691644964\n",
      "Mean Absolute Percentage Error (Unscaled): 0.016029600633783773\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model = load_model('modelmk2-2.keras')\n",
    "\n",
    "\n",
    "x, y = loadData(stock=stock['TSLA'], sequence_length=40, prediction_length=1)\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = model.predict(x)\n",
    "# Reshape the arrays to be 2-dimensional\n",
    "y = y.reshape(-1, y.shape[-1])\n",
    "y_val_pred = y_val_pred.reshape(-1, y_val_pred.shape[-1])\n",
    "\n",
    "\n",
    "# Inverse transform the predictions and actual values\n",
    "y_val_pred_unscaled = scaler.inverse_transform(y_val_pred)\n",
    "y_unscaled = scaler.inverse_transform(y)\n",
    "# Calculate MSE on the unscaled data\n",
    "mse_unscaled = mean_squared_error(y_unscaled, y_val_pred_unscaled)\n",
    "print(f'Mean Squared Error (Unscaled): {mse_unscaled}')\n",
    "\n",
    "# Calculate MAPE on the unscaled data\n",
    "mape_unscaled = mean_absolute_percentage_error(y_unscaled, y_val_pred_unscaled)\n",
    "print(f'Mean Absolute Percentage Error (Unscaled): {mape_unscaled}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3028/3028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step\n",
      "Average Accuracy: 0.51\n",
      "\u001b[1m3025/3025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 14ms/step\n",
      "Average Accuracy: 0.50\n",
      "\u001b[1m2535/2535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 14ms/step\n",
      "Average Accuracy: 0.52\n",
      "\u001b[1m2484/2484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 14ms/step\n",
      "Average Accuracy: 0.52\n",
      "\u001b[1m3606/3606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 14ms/step\n",
      "Average Accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "calculateAccuracy(model, stock['AAPL'], 64)\n",
    "calculateAccuracy(model, stock['AMZN'], 64)\n",
    "calculateAccuracy(model, stock['META'], 64)\n",
    "calculateAccuracy(model, stock['MSFT'], 64)\n",
    "calculateAccuracy(model, stock['TSLA'], 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more units and filters to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">404,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">541,840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">58,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,125</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m49,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m260\u001b[0m)        │       \u001b[38;5;34m404,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m260\u001b[0m)            │       \u001b[38;5;34m541,840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │        \u001b[38;5;34m58,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m1,125\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_5 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,057,317</span> (4.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,057,317\u001b[0m (4.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,057,317</span> (4.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,057,317\u001b[0m (4.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 68ms/step - loss: 0.0230 - val_loss: 0.0011 - learning_rate: 6.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 68ms/step - loss: 0.0012 - val_loss: 0.0011 - learning_rate: 6.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 68ms/step - loss: 0.0011 - val_loss: 0.0010 - learning_rate: 6.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 67ms/step - loss: 0.0011 - val_loss: 9.9914e-04 - learning_rate: 6.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 70ms/step - loss: 0.0010 - val_loss: 0.0010 - learning_rate: 6.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 70ms/step - loss: 0.0010 - val_loss: 0.0010 - learning_rate: 6.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 70ms/step - loss: 0.0010 - val_loss: 9.8795e-04 - learning_rate: 6.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 69ms/step - loss: 0.0010 - val_loss: 9.8560e-04 - learning_rate: 6.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 68ms/step - loss: 9.7759e-04 - val_loss: 9.6323e-04 - learning_rate: 3.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 69ms/step - loss: 9.8424e-04 - val_loss: 9.5616e-04 - learning_rate: 3.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 67ms/step - loss: 9.8791e-04 - val_loss: 9.5676e-04 - learning_rate: 3.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 68ms/step - loss: 9.7730e-04 - val_loss: 9.5387e-04 - learning_rate: 3.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 71ms/step - loss: 9.6415e-04 - val_loss: 9.8489e-04 - learning_rate: 1.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 71ms/step - loss: 9.6029e-04 - val_loss: 9.4888e-04 - learning_rate: 1.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 70ms/step - loss: 9.7213e-04 - val_loss: 9.4747e-04 - learning_rate: 1.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 71ms/step - loss: 9.7274e-04 - val_loss: 9.6423e-04 - learning_rate: 1.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 72ms/step - loss: 9.5315e-04 - val_loss: 9.4923e-04 - learning_rate: 7.5000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 73ms/step - loss: 9.5602e-04 - val_loss: 9.4362e-04 - learning_rate: 7.5000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 73ms/step - loss: 9.5305e-04 - val_loss: 9.4231e-04 - learning_rate: 7.5000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 76ms/step - loss: 9.5126e-04 - val_loss: 9.4840e-04 - learning_rate: 7.5000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 74ms/step - loss: 9.5297e-04 - val_loss: 9.4077e-04 - learning_rate: 3.7500e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 73ms/step - loss: 9.5459e-04 - val_loss: 9.3994e-04 - learning_rate: 3.7500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 72ms/step - loss: 9.4733e-04 - val_loss: 9.3835e-04 - learning_rate: 3.7500e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 73ms/step - loss: 9.5287e-04 - val_loss: 9.3985e-04 - learning_rate: 3.7500e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 70ms/step - loss: 9.5107e-04 - val_loss: 9.3914e-04 - learning_rate: 1.8750e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 71ms/step - loss: 9.5167e-04 - val_loss: 9.3763e-04 - learning_rate: 1.8750e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 70ms/step - loss: 9.4655e-04 - val_loss: 9.3839e-04 - learning_rate: 1.8750e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 70ms/step - loss: 9.5425e-04 - val_loss: 9.3903e-04 - learning_rate: 1.8750e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 70ms/step - loss: 9.5219e-04 - val_loss: 9.3896e-04 - learning_rate: 9.3750e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 69ms/step - loss: 9.4888e-04 - val_loss: 9.3871e-04 - learning_rate: 9.3750e-06\n",
      "Epoch 31/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 70ms/step - loss: 9.4026e-04 - val_loss: 9.3727e-04 - learning_rate: 9.3750e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 71ms/step - loss: 9.4009e-04 - val_loss: 9.3711e-04 - learning_rate: 9.3750e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 70ms/step - loss: 9.5110e-04 - val_loss: 9.3692e-04 - learning_rate: 4.6875e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 70ms/step - loss: 9.4585e-04 - val_loss: 9.3696e-04 - learning_rate: 4.6875e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 70ms/step - loss: 9.5894e-04 - val_loss: 9.3664e-04 - learning_rate: 4.6875e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 70ms/step - loss: 9.4292e-04 - val_loss: 9.3719e-04 - learning_rate: 4.6875e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 68ms/step - loss: 9.4347e-04 - val_loss: 9.3654e-04 - learning_rate: 2.3438e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 68ms/step - loss: 9.5743e-04 - val_loss: 9.3653e-04 - learning_rate: 2.3438e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 71ms/step - loss: 9.4498e-04 - val_loss: 9.3673e-04 - learning_rate: 2.3438e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 72ms/step - loss: 9.4237e-04 - val_loss: 9.3672e-04 - learning_rate: 2.3438e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 68ms/step - loss: 9.4467e-04 - val_loss: 9.3646e-04 - learning_rate: 1.1719e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 68ms/step - loss: 9.3912e-04 - val_loss: 9.3651e-04 - learning_rate: 1.1719e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 69ms/step - loss: 9.4943e-04 - val_loss: 9.3649e-04 - learning_rate: 1.1719e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 70ms/step - loss: 9.3907e-04 - val_loss: 9.3656e-04 - learning_rate: 1.1719e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 70ms/step - loss: 9.4008e-04 - val_loss: 9.3650e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 70ms/step - loss: 9.5333e-04 - val_loss: 9.3654e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 70ms/step - loss: 9.4550e-04 - val_loss: 9.3632e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 69ms/step - loss: 9.4735e-04 - val_loss: 9.3643e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 49/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 67ms/step - loss: 9.4010e-04 - val_loss: 9.3664e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m4729/4729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 68ms/step - loss: 9.4007e-04 - val_loss: 9.3639e-04 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-6)\n",
    "checkpoint = ModelCheckpoint('modelmk2-3.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Dropout(0.2))\n",
    "# First  LSTM layer with return sequences\n",
    "model.add(LSTM(units=260, activation='relu', return_sequences=True, kernel_regularizer=l2(6e-05)))\n",
    "# Second  LSTM layer without return sequences\n",
    "model.add(LSTM(units=260, activation='relu', return_sequences=False, kernel_regularizer=l2(6e-05)))\n",
    "\n",
    "# Dense layer with 224 units\n",
    "model.add(Dense(units=224, activation='relu'))\n",
    "# model.add(Dropout(0.15))  # Dropout layer\n",
    "\n",
    "# Output Dense layer\n",
    "model.add(Dense(units=y_train.shape[1] * y_train.shape[2], activation='relu'))\n",
    "model.add(Reshape((y_train.shape[1], y_train.shape[2])))\n",
    "model.summary()\n",
    "# Compile the model with the specified learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0006), loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=64, validation_data=(x_val, y_val), callbacks=[early_stopping, lr_scheduler, checkpoint])\n",
    "\n",
    "# Print the model summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model efficacy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7212/7212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 13ms/step\n",
      "Mean Squared Error (Unscaled): 0.5081611660577526\n",
      "Mean Absolute Percentage Error (Unscaled): 0.015934510413404154\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model = load_model('modelmk2-3.keras')\n",
    "\n",
    "\n",
    "x, y = loadData(stock=stock['TSLA'], sequence_length=40, prediction_length=1)\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = model.predict(x)\n",
    "# Reshape the arrays to be 2-dimensional\n",
    "y = y.reshape(-1, y.shape[-1])\n",
    "y_val_pred = y_val_pred.reshape(-1, y_val_pred.shape[-1])\n",
    "\n",
    "\n",
    "# Inverse transform the predictions and actual values\n",
    "y_val_pred_unscaled = scaler.inverse_transform(y_val_pred)\n",
    "y_unscaled = scaler.inverse_transform(y)\n",
    "# Calculate MSE on the unscaled data\n",
    "mse_unscaled = mean_squared_error(y_unscaled, y_val_pred_unscaled)\n",
    "print(f'Mean Squared Error (Unscaled): {mse_unscaled}')\n",
    "\n",
    "# Calculate MAPE on the unscaled data\n",
    "mape_unscaled = mean_absolute_percentage_error(y_unscaled, y_val_pred_unscaled)\n",
    "print(f'Mean Absolute Percentage Error (Unscaled): {mape_unscaled}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3028/3028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 19ms/step\n",
      "Average Accuracy: 0.51\n",
      "\u001b[1m3025/3025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 20ms/step\n",
      "Average Accuracy: 0.50\n",
      "\u001b[1m2535/2535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 20ms/step\n",
      "Average Accuracy: 0.51\n",
      "\u001b[1m2484/2484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 20ms/step\n",
      "Average Accuracy: 0.52\n",
      "\u001b[1m3606/3606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 20ms/step\n",
      "Average Accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "calculateAccuracy(model, stock['AAPL'], 64)\n",
    "calculateAccuracy(model, stock['AMZN'], 64)\n",
    "calculateAccuracy(model, stock['META'], 64)\n",
    "calculateAccuracy(model, stock['MSFT'], 64)\n",
    "calculateAccuracy(model, stock['TSLA'], 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the Hyperband hyperparameter tuner to find the best model architecture: 1-3 Conv1d layers tuning number of filters, 1-3 LSTM layers tuning kernal regularization and number of units, 0-2 dense layers tuning the number of units, and then also tuning learning rate: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 69 Complete [00h 46m 06s]\n",
      "val_loss: 0.0009449672070331872\n",
      "\n",
      "Best val_loss So Far: 0.0008965398883447051\n",
      "Total elapsed time: 2d 13h 04m 23s\n",
      "\n",
      "Search: Running Trial #70\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "3                 |1                 |conv_layers\n",
      "256               |64                |filters_0\n",
      "2                 |1                 |lstm_layers\n",
      "512               |128               |lstm_units_0\n",
      "7.8472e-06        |1.0572e-06        |l2_0\n",
      "1                 |2                 |dense_layers\n",
      "0.0002858         |0.00080814        |learning_rate\n",
      "256               |192               |filters_1\n",
      "384               |64                |lstm_units_1\n",
      "4.5748e-05        |3.3546e-06        |l2_1\n",
      "448               |128               |lstm_units_2\n",
      "4.6963e-05        |5.533e-06         |l2_2\n",
      "128               |448               |dense_units_0\n",
      "128               |192               |filters_2\n",
      "384               |64                |dense_units_1\n",
      "10                |30                |tuner/epochs\n",
      "4                 |10                |tuner/initial_epoch\n",
      "2                 |3                 |tuner/bracket\n",
      "1                 |3                 |tuner/round\n",
      "0060              |0047              |tuner/trial_id\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dupaw\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 34 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "\u001b[1m 280/4729\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:23\u001b[0m 154ms/step - loss: 0.0013"
     ]
    }
   ],
   "source": [
    "# Define Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-6)\n",
    "checkpoint = ModelCheckpoint('modelmk2-4.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    \n",
    "    # Conv1D layers\n",
    "    for i in range(hp.Int('conv_layers', 1, 3)):\n",
    "        model.add(Conv1D(filters=hp.Int(f'filters_{i}', 32, 256, step=32),\n",
    "                         kernel_size=3, activation='relu'))\n",
    "    \n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # LSTM layers\n",
    "    num_lstm_layers = hp.Int('lstm_layers', 1, 3)\n",
    "    for i in range(num_lstm_layers):\n",
    "        model.add(LSTM(units=hp.Int(f'lstm_units_{i}', 64, 512, step=64),\n",
    "                    activation='relu', return_sequences=(i < num_lstm_layers - 1),\n",
    "                    kernel_regularizer=l2(hp.Float(f'l2_{i}', 1e-6, 1e-4, sampling='LOG'))))\n",
    "\n",
    "    \n",
    "    # Dense layers\n",
    "    for i in range(hp.Int('dense_layers', 0, 2)):\n",
    "        model.add(Dense(units=hp.Int(f'dense_units_{i}', 64, 512, step=64), activation='relu'))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(units=y_train.shape[1] * y_train.shape[2], activation='relu'))\n",
    "    model.add(Reshape((y_train.shape[1], y_train.shape[2])))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Float('learning_rate', 1e-5, 1e-3, sampling='LOG')),\n",
    "                  loss='mse')\n",
    "    return model\n",
    "\n",
    "tuner = Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=30,\n",
    "    factor=3,\n",
    "    hyperband_iterations=1,\n",
    "    directory=r\"C:\\Users\\dupaw\\Desktop\\projects\\algotrading\",\n",
    "    project_name='stock_prediction_pt2'\n",
    ")\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=30, validation_data=(x_val, y_val), callbacks=[early_stopping, lr_scheduler, checkpoint], batch_size=64)\n",
    "\n",
    "# # Compile the model with the specified learning rate\n",
    "# model.compile(optimizer=Adam(learning_rate=0.0003), loss='mse')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
